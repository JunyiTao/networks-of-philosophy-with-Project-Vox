{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Present Philosopher info on Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://en.wikipedia.org/wiki/List_of_philosophers_(A-C)', 'https://en.wikipedia.org/wiki/List_of_philosophers_(D-H)', 'https://en.wikipedia.org/wiki/List_of_philosophers_(I-Q)', 'https://en.wikipedia.org/wiki/List_of_philosophers_(R-Z)']\n",
    "\n",
    "wiki_philo_list = []\n",
    "\n",
    "for url in urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    philosophers_list = []\n",
    "    # start, end = False, False\n",
    "\n",
    "    for i in soup.find_all('li'):\n",
    "        # print(i.text)\n",
    "        if i.text:\n",
    "            if i.text[-1] == \"]\" or i.text[-1] == \")\":\n",
    "                wiki_philo_list.append(i.text)\n",
    "\n",
    "print(len(wiki_philo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: 1804\n",
      "set: 1798\n",
      "Samuel Johnson (1649–1703)[d]\n",
      "Samuel Johnson (1696–1772)[b]\n",
      "Samuel Johnson (1709–1784)[b][c][d]\n",
      "Mao Zedong (or Mao Tse-tung) (1893–1976)[a]\n",
      "Philo of Larissa (1st century BC)[d][e]\n",
      "Philo of Larissa (154 – 84 BC)[b]\n",
      "Vasily Rozanov (1856–1919)\n",
      "Claude Henri de Rouvroy, Comte de Saint-Simon (1760–1825)\n",
      "Vasily Rozanov (1856–1919)[4]\n",
      "Claude Henri de Rouvroy, Comte de Saint-Simon (1760–1825)[1][3][4]\n",
      "Mao Zedong (1893–1976)\n",
      "list: 1800\n",
      "set: 1800\n"
     ]
    }
   ],
   "source": [
    "from function import check_dupl_ent\n",
    "from function import handle_cornercase_1\n",
    "\n",
    "check_dupl_ent(wiki_philo_list)\n",
    "wiki_philo_checked_list = handle_cornercase_1(wiki_philo_list)\n",
    "check_dupl_ent(wiki_philo_checked_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import get_wiki_philo_ent_1\n",
    "wiki_philo_ent_dict = get_wiki_philo_ent_1(wiki_philo_checked_list)\n",
    "print(len(wiki_philo_ent_dict))\n",
    "pickle.dump( wiki_philo_ent_dict, open( \"wiki_philo_ent_dict.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "womne philosopher list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_women_philosophers\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "start_ent = \"Lopamudra (born 1100 BCE)\"\n",
    "end_ent = \"Jan Zwicky (born 1955)\"\n",
    "start, end = False, False\n",
    "\n",
    "wiki_womenPhilo_ent_list = []\n",
    "for i in soup.find_all('li'):\n",
    "    if start_ent in i.text:\n",
    "        start = True\n",
    "    \n",
    "    if start and not end:\n",
    "        # print(i.text)\n",
    "        wiki_womenPhilo_ent_list.append(i.text)\n",
    "\n",
    "    if end_ent in i.text:\n",
    "        end = True\n",
    "\n",
    "print(len(wiki_womenPhilo_ent_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "from function import handle_corner_cases_2\n",
    "from function import get_wiki_philo_ent_2\n",
    "\n",
    "wiki_womenPhilo_checked_ent_list = handle_corner_cases_2(wiki_womenPhilo_ent_list)\n",
    "print(len(wiki_womenPhilo_checked_ent_list))\n",
    "# wiki_womenPhilo_checked_ent_list\n",
    "wiki_womenPhilo_ent_dict = get_wiki_philo_ent_2(wiki_womenPhilo_checked_ent_list)\n",
    "# wiki_womenPhilo_ent_dict\n",
    "print(len(wiki_womenPhilo_ent_dict))\n",
    "\n",
    "pickle.dump( wiki_womenPhilo_ent_dict, open( \"/wiki_womenPhilo_ent_dict.p\", \"wb\" ) )\n",
    "# pickle.load()\n",
    "# pickle.dump( wiki_philo_ent_dict, open( \"wiki_philo_ent_dict.p\", \"wb\" ) )\n",
    "wiki_philo_ent_dict =  pickle.load( open(\"unsure_lists/wiki_philo_ent_dict.p\", \"rb\" ) )\n",
    "wiki_womenPhilo_ent_dict = pickle.load( open(\"unsure_lists/wiki_womenPhilo_ent_dict.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two philo lists + add gender\n",
    "\n",
    "*Note*: add gender now because we want to check and clean the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = list(wiki_womenPhilo_ent_dict)\n",
    "b = list(wiki_philo_ent_dict)\n",
    "\n",
    "included_womenPhilo_list = list(set(a) & set(b))\n",
    "excluded_womenPhilo_list = [i for i in a if i not in b]\n",
    "menPhilo_list = [i for i in b if i not in included_womenPhilo_list]\n",
    "\n",
    "c1 = a + menPhilo_list\n",
    "c2 = b + excluded_womenPhilo_list\n",
    "print(len(c1) == len(c2))\n",
    "print([i for i in c2 if i not in c1] == [])\n",
    "\n",
    "full_wikiPhilo_list = c1\n",
    "\n",
    "\n",
    "pickle.dump(full_wikiPhilo_list, open( \"full_wikiPhilo_list.p\", \"wb\" ) )\n",
    "pickle.dump(excluded_womenPhilo_list, open( \"excluded_womenPhilo_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women philosophers listed 261\n",
      "women philosophers included in the main list: 49\n",
      "philosophers listed in the main list: 1800\n"
     ]
    }
   ],
   "source": [
    "a = list(wiki_womenPhilo_ent_dict)\n",
    "b = list(wiki_philo_ent_dict)\n",
    "\n",
    "included_womenPhilo_list = list(set(a) & set(b))\n",
    "excluded_womenPhilo_list = [i for i in a if i not in b]\n",
    "menPhilo_list = [i for i in b if i not in included_womenPhilo_list]\n",
    "\n",
    "print(\"women philosophers listed\",len(a))\n",
    "print(\"women philosophers included in the main list:\",len(included_womenPhilo_list))\n",
    "print(\"philosophers listed in the main list:\",len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: integrate information associated with unchecked entities here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_philo_group_list = []\n",
    "\n",
    "for i in full_wikiPhilo_list:\n",
    "    info_dict = {}\n",
    "    info_dict['entity'] = i\n",
    "    if i in included_womenPhilo_list:\n",
    "        info_dict['gender_listed'] = 0\n",
    "        info_dict['inclusion'] = \"main: included; women: included\"\n",
    "    elif i in excluded_womenPhilo_list:\n",
    "        info_dict['gender_listed'] = 0\n",
    "        info_dict['inclusion'] = \"main: excluded; women: included\"\n",
    "    elif i in menPhilo_list:\n",
    "        info_dict['gender_listed'] = 1\n",
    "        info_dict['inclusion'] = \"main: included\"\n",
    "    wiki_philo_group_list.append(info_dict)\n",
    "\n",
    "wiki_philo_group_list\n",
    "pickle.dump(wiki_philo_group_list, open( \"wiki_philo_group_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 49\n",
      "2061\n",
      "1679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Information listed together with the entity lists. birthDate, extra info, etc.\n",
    "\n",
    "dl1 = wiki_womenPhilo_ent_dict.items()\n",
    "dl2 = wiki_philo_ent_dict.items()\n",
    "\n",
    "k1 = wiki_womenPhilo_ent_dict.keys()\n",
    "k2 = wiki_philo_ent_dict.keys()\n",
    "\n",
    "ent_list = set( list(k1) + list(k2))\n",
    "ovrl_list = list(set(list(k1)) & set(list(k2)))\n",
    "print(len(ent_list), len(ovrl_list))\n",
    "\n",
    "info_list = list(dl1) + list(dl2)\n",
    "print(len(info_list))\n",
    "\n",
    "# do the included women have the same info in two lists?\n",
    "\n",
    "t1 = [i['time'] for i in wiki_womenPhilo_ent_dict.values()]\n",
    "t2 = [i['time'] for i in wiki_philo_ent_dict.values()]\n",
    "\n",
    "time_list = set( list(t1) + list(t2))\n",
    "print(len(time_list))\n",
    "\n",
    "# for item in info_list:\n",
    "#     if item[0] in ovrl_list:\n",
    "#         print(item)\n",
    "\n",
    "# update listed birthYear\n",
    "listed_info_dict = {}\n",
    "for ent in ent_list:\n",
    "    for i in info_list:\n",
    "        if i[0] == ent:\n",
    "            listed_info_dict[ent] = i[1]\n",
    "\n",
    "len(listed_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the information\n",
    "wiki_philo_group_list = pickle.load( open( \"wiki_philo_group_list.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "for item in wiki_philo_group_list:\n",
    "    item[\"listed_info\"] = listed_info_dict[item['entity']]\n",
    "    # print(listed_info_dict[item['entity']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_philo_group_list\n",
    "pickle.dump(wiki_philo_group_list, open( \"wiki_philo_info_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if wiki pages are accessible\n",
    "\n",
    "wikiPage = \"https://en.wikipedia.org/wiki/\"\n",
    "\n",
    "dbpage = \"https://dbpedia.org/page/\"\n",
    "\n",
    "\n",
    "**Reasons for page not existing**:\n",
    "- language\n",
    "    - no page in en.wiki\n",
    "    - different notations 拼音\n",
    "- label-name mismatch\n",
    "    - middle name \n",
    "    - suffix (xxx of xxx)\n",
    "    - multiple persons share the same name so there is a differentiater (xxx)\n",
    "\n",
    "Pattern:\n",
    "- if dbUrl and not wikiUrl => label is at least refered to by some pages\n",
    "- if not dbUrl => label doesn't exist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from function import url_checker\n",
    "from function import check_wiki_url\n",
    "\n",
    "ent_list = [d['entity'] for d in wiki_philo_group_list]\n",
    "\n",
    "checked_wikiUrl_list, problem_wikiUrl_list = check_wiki_url(ent_list)\n",
    "checked_dbUrl_list, problem_dbUrl_list = check_db_url(ent_list)\n",
    "\n",
    "\n",
    "problem_wiki_ent_list = [i.replace(\"https://en.wikipedia.org/wiki/\",\"\").replace(\"_\",\" \") for i in problem_wikiUrl_list]\n",
    "problem_db_ent_list = [i.replace(\"https://dbpedia.org/page/\",\"\").replace(\"_\",\" \") for i in problem_dbUrl_list]\n",
    "\n",
    "# check\n",
    "print([i for i in problem_wiki_ent_list if i not in ent_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For dbpedia**:\n",
    "\n",
    "    - whenever there is an en.wiki page, there's a dbpage\n",
    "    - dbpage means that this entity is at least refered by some pages\n",
    "\n",
    "Exception: https://dbpedia.org/page/Dickinson_S._Miller\n",
    "while https://en.wikipedia.org/wiki/Dickinson_Miller =automatically=> https://en.wikipedia.org/wiki/Dickinson_S._Miller\n",
    "\n",
    "=> onnly correct wiki list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the label in dbpedia and wikipedia should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(item[\"wiki_url\"])\n",
    "        # soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        # results = soup.find(id=\"firstHeading\")\n",
    "        # entity_corrected = results.text\n",
    "        \n",
    "        # if item[\"entity\"] != entity_corrected:\n",
    "        #     print(item[\"entity\"], \"|\",item[\"accessible_label\"],\"=>\",entity_corrected)\n",
    "        # put all the entities in the dict\n",
    "        # ent_dupl_dict[item[\"entity\"]] = entity_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in wiki: 66 \n",
      "not in db: 20\n",
      "in db not in wiki: 46 \n",
      "in wiki not in db: 0\n"
     ]
    }
   ],
   "source": [
    "# examine the relationships between dbpedia and wikipedia\n",
    "d1 = [i for i in problem_wiki_ent_list if i not in problem_db_ent_list]\n",
    "d2 = [i for i in problem_db_ent_list if i not in problem_wiki_ent_list]\n",
    "print(\n",
    "    \"not in wiki:\",len(problem_wiki_ent_list), \n",
    "    \"\\nnot in db:\",len(problem_db_ent_list)\n",
    "    )\n",
    "print(\n",
    "    \"in db not in wiki:\",len(d1), \n",
    "    \"\\nin wiki not in db:\",len(d2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle wrong urls, by 06/03/2022\n",
    "\n",
    "*Note:* information (\"it is wrong!”) is also very valueable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv, import corrected labels, update the dict\n",
    "\n",
    "df = pd.read_csv(\"correct_wiki_url.csv\")\n",
    "wiki_philo_info_list = pickle.load( open( \"wiki_philo_info_list.p\", \"rb\" ) )\n",
    "\n",
    "wiki_philo_corrected_list = []\n",
    "\n",
    "for item in wiki_philo_info_list:\n",
    "    ent = str(item['entity'])\n",
    "    item['refered_name'] = [ent] # the name in the list, which may be the wrong label\n",
    "\n",
    "    wiki_url = \"https://en.wikipedia.org/wiki/\"+ent.replace(\" \",\"_\")\n",
    "    db_url = \"https://dbpedia.org/page/\" + ent.replace(\" \",\"_\")\n",
    "    item['wiki_url'] = wiki_url\n",
    "    item['db_url'] = db_url\n",
    "\n",
    "    wiki_philo_corrected_list.append(item)\n",
    "\n",
    "# check\n",
    "# for item in wiki_philo_corrected_list:\n",
    "#     if item['refered_name'] != item['entity']:\n",
    "#         print(item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entity lists\n",
    "for item in wiki_philo_corrected_list:\n",
    "    ent = str(item['entity'])\n",
    "    \n",
    "    if ent in df['wrong_label'].tolist(): # it is wrong?\n",
    "        idx = df['wrong_label'].tolist().index(ent)\n",
    "        correct_ent = df['correct_label'].iloc[idx]\n",
    "        if type(correct_ent) == str: # have it been corrected?\n",
    "            item['entity'] = correct_ent\n",
    "            wiki_url = \"https://en.wikipedia.org/wiki/\"+correct_ent.replace(\" \",\"_\")\n",
    "            db_url = \"https://dbpedia.org/page/\" + correct_ent.replace(\" \",\"_\")\n",
    "            item['wiki_url'] = wiki_url\n",
    "            item['db_url'] = db_url\n",
    "            \n",
    "        elif type(correct_ent) == float:\n",
    "            item['entity'] = \"\" # no wiki page, cannot be corrected\n",
    "            item['wiki_url'] = \"\"\n",
    "            item['db_url'] = \"\"\n",
    "\n",
    "# check\n",
    "COUNT_1, COUNT_2 = 0, 0\n",
    "\n",
    "corrected_ent_list = []\n",
    "for i in df['correct_label']:\n",
    "    if type(i) == str:\n",
    "        corrected_ent_list.append(i)\n",
    "\n",
    "for item in wiki_philo_corrected_list:\n",
    "    \n",
    "    if item['entity'] != item['refered_name']:\n",
    "        # print(item['entity'], item['refered_name'])\n",
    "        COUNT_1 = COUNT_1 +1\n",
    "    if item['entity'] == \"\":\n",
    "        COUNT_2 = COUNT_2 +1\n",
    "    \n",
    "# print(COUNT_1, COUNT_2)\n",
    "test_1 = (COUNT_1 == len(problem_wikiUrl_list))\n",
    "test_2 = (COUNT_2 == len(df) -len(corrected_ent_list))\n",
    "if test_1 and test_2:\n",
    "    pickle.dump(wiki_philo_corrected_list, open( \"wiki_philo_corrected_list.p\", \"wb\" ) )\n",
    "else:\n",
    "    print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data (information of philosopher in DBpedia page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import get_db_philosopher\n",
    "\n",
    "for item in wiki_philo_corrected_list:\n",
    "    # print(get_db_philosopher( item['entity']))\n",
    "    item['dbpedia_info'] = get_db_philosopher( item['entity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_philo_corrected_list\n",
    "pickle.dump(wiki_philo_corrected_list, open( \"info_lists/db_philo_info_\"+time.strftime(\"%Y%m%d\")+\".p\", \"wb\" ) )\n",
    "db_philo_info_list = pickle.load( open( \"info_lists/db_philo_info_\"+time.strftime(\"%Y%m%d\")+\".p\", \"rb\" ) )\n",
    "db_philo_info_list\n",
    "db_philo_info_list = pickle.load( open( \"info_lists/db_philo_info_list.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1034793', '2157753', '38375', '2245936', '14125745', '23758', '177557', '3783415', '43583', '2016044']\n",
      "Isaac ben Judah Abravanel => Isaac Abarbanel\n",
      "Catherine Trotter Cockburn => Catharine Trotter Cockburn\n",
      "Hypatia of Alexandria => Hypatia\n",
      "Kuo Hsiang => Guo Xiang\n",
      "Philo of Megara => Philo the Dialectician\n",
      "Friedrich Schelling => Friedrich Wilhelm Joseph Schelling\n",
      "L. Susan Stebbing => Susan Stebbing\n",
      "Teresa of Avila => Teresa of Ávila\n",
      "Mary Warnock => Mary Warnock, Baroness Warnock\n",
      "{'Hypatia': 'Hypatia', 'Teresa of Ávila': 'Teresa of Ávila', 'Catharine Trotter Cockburn': 'Catharine Trotter Cockburn', 'Susan Stebbing': 'Susan Stebbing', 'Mary Warnock, Baroness Warnock': 'Mary Warnock, Baroness Warnock', 'Isaac ben Judah Abravanel': 'Isaac Abarbanel', 'Isaac Abarbanel': 'Isaac Abarbanel', 'Catherine Trotter Cockburn': 'Catharine Trotter Cockburn', 'Guo Xiang': 'Guo Xiang', 'Hypatia of Alexandria': 'Hypatia', 'Friedrich Wilhelm Joseph Schelling': 'Friedrich Wilhelm Joseph Schelling', 'Kuo Hsiang': 'Guo Xiang', 'Philo the Dialectician': 'Philo the Dialectician', 'Philo of Megara': 'Philo the Dialectician', 'Pseudo-Dionysius the Areopagite': 'Pseudo-Dionysius the Areopagite', 'Friedrich Schelling': 'Friedrich Wilhelm Joseph Schelling', 'L. Susan Stebbing': 'Susan Stebbing', 'Teresa of Avila': 'Teresa of Ávila', 'Mary Warnock': 'Mary Warnock, Baroness Warnock'}\n"
     ]
    }
   ],
   "source": [
    "# they are included because their pages can be accessed via multiple labels\n",
    "# we access each link and get the label directly from the page\n",
    "\n",
    "# print the wrong entities\n",
    "data = copy.deepcopy(db_philo_info_list)\n",
    "\n",
    "l = [item['wikiPageID'] for item in data]\n",
    "\n",
    "visited = set()\n",
    "dup = [x for x in l if x in visited or (visited.add(x) or False)]\n",
    "# print(dup)\n",
    "dup = [i for i in dup if i]\n",
    "print(dup)\n",
    "\n",
    "ent_correct_dict = {} # key: entity (wrong label), value: correct label\n",
    "for item in data:\n",
    "    if item['wikiPageID'] in dup:\n",
    "        # print(item[\"entity\"], item[\"wiki_url\"],item[\"dbpedia_info\"][\"wikiPageID\"])\n",
    "        page = requests.get(item[\"wiki_url\"])\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find(id=\"firstHeading\")\n",
    "        entity_corrected = results.text\n",
    "        \n",
    "        if item[\"entity\"] != entity_corrected:\n",
    "            print(item[\"entity\"], \"=>\",entity_corrected)\n",
    "        ent_correct_dict[item[\"entity\"]] = entity_corrected\n",
    "\n",
    "# or, if we don't want a check, just delete all of them\n",
    "print(ent_correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hypatia': ['Hypatia', 'Hypatia of Alexandria'], 'Teresa of Ávila': ['Teresa of Ávila', 'Teresa of Avila'], 'Catharine Trotter Cockburn': ['Catharine Trotter Cockburn', 'Catherine Trotter Cockburn'], 'Susan Stebbing': ['Susan Stebbing', 'L. Susan Stebbing'], 'Mary Warnock, Baroness Warnock': ['Mary Warnock, Baroness Warnock', 'Mary Warnock'], 'Isaac Abarbanel': ['Isaac ben Judah Abravanel', 'Isaac Abarbanel'], 'Guo Xiang': ['Guo Xiang', 'Kuo Hsiang'], 'Friedrich Wilhelm Joseph Schelling': ['Friedrich Wilhelm Joseph Schelling', 'Friedrich Schelling'], 'Philo the Dialectician': ['Philo the Dialectician', 'Philo of Megara'], 'Pseudo-Dionysius the Areopagite': ['Pseudo-Dionysius the Areopagite']}\n"
     ]
    }
   ],
   "source": [
    "ent_correct_inv_dict  = {}  # correct entity: wrong/correct labels\n",
    "\n",
    "for key, value in ent_correct_dict.items():\n",
    "    if value not in ent_correct_inv_dict:\n",
    "        ent_correct_inv_dict[value] = [key]\n",
    "    else:\n",
    "        ent_correct_inv_dict[value].append(key)\n",
    "\n",
    "\n",
    "print(ent_correct_inv_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not sure if all the corrected entities are covered in the dup list (probably all the labels are wrong)\n",
    "# keep the other properties\n",
    "resolved_list = []\n",
    "\n",
    "for item in data:\n",
    "    item[\"accessible_label\"] = [item[\"refered_name\"]]\n",
    "    new_dict = {}\n",
    "\n",
    "    if item[\"entity\"] in ent_correct_dict: # if included in the problematic lists\n",
    "        # Removing dictionary from list of dictionaries\n",
    "        data.remove(item)\n",
    "        if item[\"entity\"] in ent_correct_inv_dict: # delete the nodes if their labels are right\n",
    "\n",
    "            continue\n",
    "        \n",
    "        else: # correct those whose labels are wrong\n",
    "            ent = item[\"entity\"]\n",
    "            item[\"entity\"] = ent_correct_dict[ent] # correct it\n",
    "            print(ent, \"=>\",item[\"entity\"])\n",
    "            item[\"wiki_url\"] = \"https://en.wikipedia.org/wiki/\"+item[\"entity\"].replace(\" \",\"_\")\n",
    "            item[\"db_url\"] = \"https://dbpedia.org/page/\"+item[\"entity\"].replace(\" \",\"_\")\n",
    "\n",
    "            item[\"accessible_label\"] = ent_correct_inv_dict[ item[\"entity\"] ]\n",
    "            # it is also a check of the correctness of the corrected entities\n",
    "            item['dbpedia_info'] = get_db_philosopher( item['entity'])\n",
    "            \n",
    "            print(item)\n",
    "            resolved_list.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open( \"info_lists/db_philo_info_resolved_list.p\", \"wb\" ) )\n",
    "pickle.dump(resolved_list, open( \"check_lists/label_resolve_list.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75d3cd09312a5c5e4ea9ca503f0de7315f2a6856e8eb6e1d90df3dbfd3ff1a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
